{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-BeOChlfOfY"
   },
   "source": [
    "## Mini-Project 3:  Computer Vision using GPU and Transfer Learning\n",
    "\n",
    "\n",
    "#### CSC 180 Intelligent Systems (Fall 2021)\n",
    "\n",
    "#### Dr. Haiquan Chen, California State University, Sacramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rENMVFFibA3H"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Seran Gemechu  ID: 219954918\n",
    "# Harish Kandaswamy  ID: \n",
    "# CSC 180\n",
    "# Project 3\n",
    "# Oct, 28, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlFpkRqpfOfa"
   },
   "source": [
    "\n",
    "## Helpful Functions for Tensorflow (Little Gems)\n",
    "\n",
    "The following functions will be used with TensorFlow to help preprocess the data.  They allow you to build the feature vector for a neural network. \n",
    "\n",
    "* Predictors/Inputs \n",
    "    * Fill any missing inputs with the median for that column.  Use **missing_median**.\n",
    "    * Encode textual/categorical values with **encode_text_dummy**.\n",
    "    * Encode numeric values with **encode_numeric_zscore**.\n",
    "* Output\n",
    "    * Discard rows with missing outputs.\n",
    "    * Encode textual/categorical values with **encode_text_index**.\n",
    "    * Do not encode output numeric values.\n",
    "* Produce final feature vectors (x) and expected output (y) with **to_xy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FOddo2bbfOfb"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-27332ca194a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m from .utils._tags import (\n\u001b[0;32m     19\u001b[0m     \u001b[0m_DEFAULT_TAGS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\class_weight.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_deprecate_positional_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcontextlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPositiveSpectrumWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlsqr\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msparse_lsqr\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMaskedArray\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_MaskedArray\u001b[0m  \u001b[1;31m# TODO: remove in 1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \"\"\"\n\u001b[1;32m--> 391\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#       instead of `git blame -Lxxx,+x`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m from ._distn_infrastructure import (entropy, rv_discrete, rv_continuous,\n\u001b[0m\u001b[0;32m      9\u001b[0m                                     rv_frozen)\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# for root finding for continuous distribution ppf, and max likelihood estimation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_nnls\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnnls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_basinhopping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbasinhopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_linprog\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinprog_verbose_callback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_lsap\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear_sum_assignment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_differentialevolution\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdifferential_evolution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linprog.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_linprog_ip\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_linprog_ip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_linprog_simplex\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_linprog_simplex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_linprog_rs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_linprog_rs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m from ._linprog_doc import (_linprog_highs_doc, _linprog_ip_doc,\n\u001b[0;32m     27\u001b[0m                            \u001b[0m_linprog_rs_doc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_linprog_simplex_doc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linprog_rs.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msolve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_check_unknown_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_bglu_dense\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_bglu_dense\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBGLU\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mBGLU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, collections.Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qU8FIYWRVXM1"
   },
   "source": [
    "## Switch and Verify GPU\n",
    "\n",
    "### To enable GPU backend for your notebook. Runtime->Change runtime type->Hardware Accelerator->GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1s9pBa09U_zJ",
    "outputId": "f09775c8-d504-4376-ad75-091ea919e8ca"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFpkSEEDbTag"
   },
   "source": [
    "### If the above code output '/device:GPU:0',  you have switched to GPU successfully and you are ready to go. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "Kv39g9StfOff"
   },
   "source": [
    "## Part I:   Image classification without transfer learning\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0495-SoMfOfg"
   },
   "outputs": [],
   "source": [
    "#  Load cifar-10 data and split it to training and test\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# The data split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9DWyVv_efOfj",
    "outputId": "974cb1f2-efa6-4f5b-ea35-06e1f4e10e70"
   },
   "outputs": [],
   "source": [
    "# Check data shape\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "OfDjuB-_fOfr",
    "outputId": "ee9614db-ee8b-4c3f-9fe0-4081d819736a"
   },
   "outputs": [],
   "source": [
    "# Let's print out one image in the training set\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgRiH7S4fOfu"
   },
   "outputs": [],
   "source": [
    "# Convert y_train from 2D to 1D    \n",
    "\n",
    "y_train = y_train.reshape(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6MfVmrQ-fOfx",
    "outputId": "339f20d0-87b3-4f20-9071-4d8e03284f49"
   },
   "outputs": [],
   "source": [
    "# Check y shape\n",
    "\n",
    "y_train.shape\n",
    "\n",
    "\n",
    "# expected output:  (50000,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWvawslufOfz",
    "outputId": "b7d46091-1ac3-477f-8e4f-07409e7a8d93"
   },
   "outputs": [],
   "source": [
    "y_train[1]\n",
    "\n",
    "# expected output:  9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcrolrznfOf2"
   },
   "outputs": [],
   "source": [
    "# Convert y_test from 2D to 1D \n",
    "\n",
    "y_test = y_test.reshape(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iT3IYTNqfOf6",
    "outputId": "f71dd4b2-b9c9-47fb-a9d4-87c0ab017808"
   },
   "outputs": [],
   "source": [
    "y_test.shape\n",
    "\n",
    "# expected output: (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-lWtPlHfOf9"
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to one hot format\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFzHf8QefOgC"
   },
   "outputs": [],
   "source": [
    "# Convert data from int to float and normalize it\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXXjBVW1lDt1"
   },
   "source": [
    "###  Write your code in the cell below to create a CNN model which contains the following types of operations (layers):   \n",
    "\n",
    "- Conv2D\n",
    "- Activation\n",
    "- MaxPooling2D\n",
    "- Flatten\n",
    "- Dropout\n",
    "- Dense\n",
    "\n",
    "### (optional) You are also encouraged to create multiple models with different activiation functions, different numbers of neurons and layers for performance comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grVEwQfQfOgE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, \n",
    "                 kernel_size=(3, 3), \n",
    "                 strides=(1, 1), \n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25)) \n",
    "        \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=Adam(learning_rate=0.001, decay=1e-6), metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FekC4kgffOgG",
    "outputId": "fb4c2650-e533-4892-bfb4-b47aad6988d6"
   },
   "outputs": [],
   "source": [
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVNwHr_AmKJi"
   },
   "source": [
    "### Write your code in the cell below for compile, earlystopping and fit. Notice that you should use earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUxCqaaZfOgI",
    "outputId": "ff18a409-b379-4e37-f405-bbc92348ef33"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "batch_size = 128\n",
    "\n",
    "model.fit(x_train, y_train,     \n",
    "          batch_size=batch_size,\n",
    "          epochs=20,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xigd26XOoU-F"
   },
   "source": [
    "### Write your code in the cell below to print out the Precision, Recall,  F1 score, and classification_*report*\n",
    "\n",
    "### Include your findings in the project report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_92T0bsfOgQ",
    "outputId": "3654497b-2df9-40c3-9491-c873eda8d6ff"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred)\n",
    "print('Accuracy: {}'.format(score))\n",
    "\n",
    "\n",
    "f1 = metrics.f1_score(y_true, pred, average='weighted')\n",
    "print('Averaged F1: {}'.format(f1))\n",
    "\n",
    "           \n",
    "print(metrics.classification_report(y_true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQEPj16-oSiR"
   },
   "source": [
    "### Write your code in the cell below to show 3-5 images in the test set as well as their true labels and their labels predicted by your model.\n",
    "\n",
    "### Include your findings in the project report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "id": "nAQGEaq28THB",
    "outputId": "8befbd46-71a7-4e59-9318-7b0912eb11a7"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, pred)\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgBnw9dRfOgS"
   },
   "source": [
    "\n",
    "\n",
    "## Part II:   CNN model with Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9rvtqrsfOgT",
    "outputId": "59e9e95e-7434-414b-f756-2fb72ef454e3"
   },
   "outputs": [],
   "source": [
    "# We load data again.   The data split between train and test sets:\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpeUNdq4m9IV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGSxqVVypDiX"
   },
   "source": [
    "### Here we would like to use one pre-trained model called VGG16.   For more details on VGG16, please go to https://neurohive.io/en/popular-networks/vgg16/\n",
    "\n",
    "\n",
    "### VGG16 supports down to 48x48 images as an input. However, the resolution of our images is too low, which is (32, 32) so we need to increase the resolution.   This is called upsampling. \n",
    "\n",
    "\n",
    "\n",
    "### Find a way to do upsampling for each image to increase its resolution from 32x32 to 64x64. One option is to use the function resize(), which is provided by scikit-image library (https://scikit-image.org/)\n",
    "\n",
    "\n",
    "### Hints: \n",
    "\n",
    "#### (1) If you use resize() in scikit-image, that function also normalizes the input image so you may not want to normalize twice.\n",
    "\n",
    "#### Learn from the examples here:  https://scikit-image.org/docs/stable/auto_examples/transform/plot_rescale.html\n",
    "\n",
    "#### (2) Apply upsampling to x_train and x_test seperately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWwBKsh-fOgX"
   },
   "outputs": [],
   "source": [
    "import skimage.transform\n",
    "\n",
    "new_x_train = []\n",
    "\n",
    "for image in x_train:\n",
    "  newImage = skimage.transform.resize(image, (64, 64))      # note that resize() also normalizes your image\n",
    "  new_x_train.append(newImage)\n",
    "  \n",
    "\n",
    "# this code may take about 3 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaQ8rcNDfOga"
   },
   "outputs": [],
   "source": [
    "new_x_train = np.asarray(new_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jm6hMVrqfOgc",
    "outputId": "c4e2cdce-64a3-4afd-a385-06f27be85b9d"
   },
   "outputs": [],
   "source": [
    "new_x_train.shape\n",
    "\n",
    "\n",
    "# expected output:  (50000, 64, 64, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0s0-oaKDfOgf"
   },
   "outputs": [],
   "source": [
    "new_x_test = []\n",
    "\n",
    "for image in x_test:\n",
    "  newImage = skimage.transform.resize(image, (64, 64))\n",
    "  new_x_test.append(newImage)\n",
    "\n",
    "\n",
    "  # this code may take about 2 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwYHdSo0fOgh"
   },
   "outputs": [],
   "source": [
    "new_x_test = np.asarray(new_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tmw0t9UzfOgk",
    "outputId": "4c334721-9aa5-4de8-b462-4567c2f72621"
   },
   "outputs": [],
   "source": [
    "new_x_test.shape\n",
    "\n",
    "\n",
    "# expected output:  (10000, 64, 64, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPjFo2oyqlGO"
   },
   "source": [
    "###Write your code in the cell below to do the following:\n",
    "\n",
    "- First convert y_train and y_test from 2D to 1D by using reshape() function \n",
    "- Next apply one-hot encoding to y_train and y_test by using tf.keras.utils.to_categorical() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQuVaf2pkRdr"
   },
   "outputs": [],
   "source": [
    "# Convert y_train, y_test from 2D to 1D    \n",
    "y_train = y_train.reshape(50000)\n",
    "y_test = y_test.reshape(10000)\n",
    "\n",
    "# Convert class vectors to one hot format\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_pLuCNjqvbf",
    "outputId": "5e1921f6-5299-4671-b52f-c52f4f8898b2"
   },
   "outputs": [],
   "source": [
    "# double check shape\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# expected output:  (50000, 10)\n",
    "# expected output:  (10000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-bzRNdjfOgy"
   },
   "source": [
    "###  Load the pre-trained VGG16 model.  Write your code in the cell below to add each layer in VGG16 (excluding the top layers) to your new model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HLwE00VfOgz",
    "outputId": "6c0d8c3e-134c-4987-b058-49d7d9f90f56"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))   #  first hidden layer\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "for layer in vgg_model.layers:\n",
    "  model.add(layer)\n",
    "\n",
    "# print out the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ki8D32hrl3E"
   },
   "source": [
    "### Write your code in the cell below to freeze the weights in each layer in the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_oqboGwfOg1"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YArrSsS4rt_t"
   },
   "source": [
    "###  Write your code in the cell below to add some \"Dense\" layers as top layers.\n",
    "\n",
    "- Donot forget the output layer\n",
    "- Choose the right activation fucntion for the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fphbz0FhfOg3",
    "outputId": "a37c831d-62b9-4d09-9d14-a5495217fc22"
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# Add some \"Dense\" layers here, including output layer\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDOG92fcr1m8"
   },
   "source": [
    "\n",
    "### Write your code below for compile and fit. \n",
    "\n",
    "### Train your new model. \n",
    "\n",
    "### Notice that you should use earlystopping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWrWTc2JfOg6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=Adam(learning_rate=0.001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "training = model.fit(new_x_train, y_train,     \n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "          validation_data=(new_x_test, y_test))\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))\n",
    "# since we use GPU, the training time for each epoch for the transferred model is about 60 seconds.  Let it run for a few epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ps2CZ8Xwrz_a"
   },
   "source": [
    "### Write your code below to print out the Precision, Recall, F1 score, and classification_report\n",
    "\n",
    "### Include your findings in the project report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMRuLfS3fOg8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "pred = model.predict(new_x_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred)\n",
    "print('Accuracy: {}'.format(score))\n",
    "\n",
    "\n",
    "f1 = metrics.f1_score(y_true, pred, average='weighted')\n",
    "print('Averaged F1: {}'.format(f1))\n",
    "\n",
    "           \n",
    "print(metrics.classification_report(y_true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnYwJ1hUHA93"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, pred)\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkatwrTod_ii"
   },
   "source": [
    "### Write your code in the cell below to show 3-5 images in the test set as well as their true labels and their labels predicted by your model with transfer learning. \n",
    "\n",
    "### Include your findings in the project report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PoRepUWbd_ii"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class_name = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck',\n",
    "}\n",
    "\n",
    "for i in range(5):\n",
    "  print(\"Prediction: %s\" % (class_name[pred[i]]))\n",
    "  print(\"Actual: %s\" % (class_name[y_true[i]]))\n",
    "  pixel_array = new_x_test[i].reshape(64,64,3)\n",
    "  pixel_array = (pixel_array*64)+64\n",
    "  pixel_array = pixel_array.astype(np.uint8)\n",
    "  img = Image.fromarray(pixel_array, 'RGB')\n",
    "  img = img.resize((256,256))\n",
    "  display(img)\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3YyM61tJEZml"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "CSC180_TL_Cifar10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
