{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "CSC180_TLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-BeOChlfOfY"
      },
      "source": [
        "## Mini-Project 3:  Computer Vision using GPU and Transfer Learning\n",
        "\n",
        "\n",
        "#### CSC 180 Intelligent Systems (Fall 2021)\n",
        "\n",
        "#### Dr. Haiquan Chen, California State University, Sacramento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rENMVFFibA3H"
      },
      "source": [
        "\n",
        "# Seran Gemechu  ID: 219954918\n",
        "# Harish Kandaswamy  ID: \n",
        "# CSC 180\n",
        "# Project 3\n",
        "# Oct, 28, 2021"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlFpkRqpfOfa"
      },
      "source": [
        "\n",
        "## Helpful Functions for Tensorflow (Little Gems)\n",
        "\n",
        "The following functions will be used with TensorFlow to help preprocess the data.  They allow you to build the feature vector for a neural network. \n",
        "\n",
        "* Predictors/Inputs \n",
        "    * Fill any missing inputs with the median for that column.  Use **missing_median**.\n",
        "    * Encode textual/categorical values with **encode_text_dummy**.\n",
        "    * Encode numeric values with **encode_numeric_zscore**.\n",
        "* Output\n",
        "    * Discard rows with missing outputs.\n",
        "    * Encode textual/categorical values with **encode_text_index**.\n",
        "    * Do not encode output numeric values.\n",
        "* Produce final feature vectors (x) and expected output (y) with **to_xy**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOddo2bbfOfb"
      },
      "source": [
        "from collections.abc import Sequence\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = \"{}-{}\".format(name, x)\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
        "def encode_text_index(df, name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    df[name] = le.fit_transform(df[name])\n",
        "    return le.classes_\n",
        "\n",
        "\n",
        "# Encode a numeric column as zscores\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the median\n",
        "def missing_median(df, name):\n",
        "    med = df[name].median()\n",
        "    df[name] = df[name].fillna(med)\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the default\n",
        "def missing_default(df, name, default_value):\n",
        "    df[name] = df[name].fillna(default_value)\n",
        "\n",
        "\n",
        "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "        if x != target:\n",
        "            result.append(x)\n",
        "    # find out the type of the target column. \n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
        "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        # Classification\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
        "    else:\n",
        "        # Regression\n",
        "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "\n",
        "# Regression chart.\n",
        "def chart_regression(pred,y,sort=True):\n",
        "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
        "    if sort:\n",
        "        t.sort_values(by=['y'],inplace=True)\n",
        "    a = plt.plot(t['y'].tolist(),label='expected')\n",
        "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
        "    plt.ylabel('output')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Remove all rows where the specified column is +/- sd standard deviations\n",
        "def remove_outliers(df, name, sd):\n",
        "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
        "    df.drop(drop_rows, axis=0, inplace=True)\n",
        "\n",
        "\n",
        "# Encode a column to a range between normalized_low and normalized_high.\n",
        "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
        "                         data_low=None, data_high=None):\n",
        "    if data_low is None:\n",
        "        data_low = min(df[name])\n",
        "        data_high = max(df[name])\n",
        "\n",
        "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
        "               * (normalized_high - normalized_low) + normalized_low\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU8FIYWRVXM1"
      },
      "source": [
        "## Switch and Verify GPU\n",
        "\n",
        "### To enable GPU backend for your notebook. Runtime->Change runtime type->Hardware Accelerator->GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1s9pBa09U_zJ",
        "outputId": "cd497da8-bc80-41db-a11a-3d4c4d2ef475"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFpkSEEDbTag"
      },
      "source": [
        "### If the above code output '/device:GPU:0',  you have switched to GPU successfully and you are ready to go. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Kv39g9StfOff"
      },
      "source": [
        "## Part I:   Image classification without transfer learning\n",
        "\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0495-SoMfOfg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef80c49e-525a-43cf-f0db-39aa071ac17b"
      },
      "source": [
        "#  Load cifar-10 data and split it to training and test\n",
        "\n",
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "# The data split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "170508288/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DWyVv_efOfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa9485a-0f43-486a-9cd6-b8fad42ae6ce"
      },
      "source": [
        "# print out data shape\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_test shape:', y_test.shape)\n",
        "\n",
        "\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3)\n",
            "y_test shape: (10000, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_Z_IKevu2Ji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53604ebb-963e-4dd8-e702-37a36dd819a4"
      },
      "source": [
        "# print out a random image in x_train as numpy array\n",
        "x_train[15]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[100, 168, 231],\n",
              "        [100, 168, 229],\n",
              "        [101, 167, 230],\n",
              "        ...,\n",
              "        [ 95, 165, 231],\n",
              "        [ 94, 165, 228],\n",
              "        [ 95, 167, 229]],\n",
              "\n",
              "       [[103, 170, 230],\n",
              "        [103, 168, 228],\n",
              "        [104, 168, 226],\n",
              "        ...,\n",
              "        [ 97, 167, 229],\n",
              "        [ 97, 166, 227],\n",
              "        [ 97, 168, 229]],\n",
              "\n",
              "       [[107, 174, 233],\n",
              "        [106, 172, 230],\n",
              "        [106, 173, 229],\n",
              "        ...,\n",
              "        [100, 170, 230],\n",
              "        [100, 170, 230],\n",
              "        [101, 172, 232]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[165, 178, 177],\n",
              "        [159, 170, 167],\n",
              "        [167, 177, 170],\n",
              "        ...,\n",
              "        [ 75, 117, 154],\n",
              "        [ 75, 120, 157],\n",
              "        [ 72, 120, 158]],\n",
              "\n",
              "       [[158, 174, 172],\n",
              "        [173, 186, 182],\n",
              "        [182, 193, 188],\n",
              "        ...,\n",
              "        [ 76, 119, 154],\n",
              "        [ 75, 119, 153],\n",
              "        [ 77, 121, 154]],\n",
              "\n",
              "       [[161, 176, 174],\n",
              "        [162, 176, 172],\n",
              "        [160, 171, 169],\n",
              "        ...,\n",
              "        [ 98, 137, 167],\n",
              "        [129, 160, 183],\n",
              "        [162, 185, 202]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbcMvRhqvWAc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "2e77db1e-e00a-46ca-bd48-20e4eb6ed0d4"
      },
      "source": [
        "# print it out as image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.imshow(x_train[15])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2b9ea630d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMwUTdqp0rUJ"
      },
      "source": [
        "# Convert y_train from 2D to 1D \n",
        "\n",
        "y_train = y_train.reshape(50000)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojvUNZgG0xVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6ac224-4c84-4fd5-e976-fafb35cc83c2"
      },
      "source": [
        "y_train.shape\n",
        "\n",
        "# expected output: (50000,)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcrolrznfOf2"
      },
      "source": [
        "# Convert y_test from 2D to 1D \n",
        "\n",
        "y_test = y_test.reshape(10000)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT3IYTNqfOf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0128af6d-0c56-406a-8289-5ecc7f65c336"
      },
      "source": [
        "y_test.shape\n",
        "\n",
        "# expected output: (10000,)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-lWtPlHfOf9"
      },
      "source": [
        "# Convert class vectors to one hot format\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFzHf8QefOgC"
      },
      "source": [
        "# Convert data from int to float and normalize it\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXXjBVW1lDt1"
      },
      "source": [
        "###  Write your code in the cell below to create a CNN model which contains the following types of operations (layers):   \n",
        "\n",
        "- Conv2D\n",
        "- Activation\n",
        "- MaxPooling2D\n",
        "- Flatten\n",
        "- Dropout\n",
        "- Dense\n",
        "\n",
        "### (optional) You are also encouraged to create multiple models with different activiation functions, different numbers of neurons and layers for performance comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grVEwQfQfOgE"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, \n",
        "                 kernel_size=(3, 3), \n",
        "                 strides=(1, 1), \n",
        "                 padding='same',\n",
        "                 activation='relu',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25)) \n",
        "        \n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=Adam(learning_rate=0.001, decay=1e-6), metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FekC4kgffOgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786fafd2-5c32-4643-f3c4-613b5f7786d9"
      },
      "source": [
        "# Print model summary\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               8389120   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 8,413,642\n",
            "Trainable params: 8,413,642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVNwHr_AmKJi"
      },
      "source": [
        "### Write your code in the cell below for compile, earlystopping and fit. Notice that you should use earlystopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUxCqaaZfOgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b65e45dd-7505-4d19-e51c-0903b0d646e6"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "batch_size = 128\n",
        "\n",
        "model.fit(x_train, y_train,     \n",
        "          batch_size=batch_size,\n",
        "          epochs=20,\n",
        "          verbose=2,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "391/391 - 40s - loss: 1.4130 - accuracy: 0.4937 - val_loss: 1.0488 - val_accuracy: 0.6295\n",
            "Epoch 2/20\n",
            "391/391 - 9s - loss: 1.0360 - accuracy: 0.6354 - val_loss: 0.9495 - val_accuracy: 0.6662\n",
            "Epoch 3/20\n",
            "391/391 - 9s - loss: 0.8867 - accuracy: 0.6896 - val_loss: 0.8898 - val_accuracy: 0.6816\n",
            "Epoch 4/20\n",
            "391/391 - 9s - loss: 0.7838 - accuracy: 0.7252 - val_loss: 0.8483 - val_accuracy: 0.6998\n",
            "Epoch 5/20\n",
            "391/391 - 9s - loss: 0.6857 - accuracy: 0.7598 - val_loss: 0.8110 - val_accuracy: 0.7177\n",
            "Epoch 6/20\n",
            "391/391 - 9s - loss: 0.5983 - accuracy: 0.7898 - val_loss: 0.8104 - val_accuracy: 0.7242\n",
            "Epoch 7/20\n",
            "391/391 - 9s - loss: 0.5263 - accuracy: 0.8138 - val_loss: 0.8077 - val_accuracy: 0.7287\n",
            "Epoch 8/20\n",
            "391/391 - 9s - loss: 0.4613 - accuracy: 0.8362 - val_loss: 0.8325 - val_accuracy: 0.7284\n",
            "Epoch 9/20\n",
            "391/391 - 9s - loss: 0.4013 - accuracy: 0.8583 - val_loss: 0.8455 - val_accuracy: 0.7288\n",
            "Epoch 10/20\n",
            "391/391 - 9s - loss: 0.3505 - accuracy: 0.8770 - val_loss: 0.8737 - val_accuracy: 0.7335\n",
            "Epoch 11/20\n",
            "391/391 - 9s - loss: 0.3104 - accuracy: 0.8912 - val_loss: 0.8815 - val_accuracy: 0.7343\n",
            "Epoch 12/20\n",
            "391/391 - 9s - loss: 0.2780 - accuracy: 0.9015 - val_loss: 0.9108 - val_accuracy: 0.7363\n",
            "Epoch 13/20\n",
            "391/391 - 9s - loss: 0.2511 - accuracy: 0.9119 - val_loss: 0.9416 - val_accuracy: 0.7355\n",
            "Epoch 14/20\n",
            "391/391 - 9s - loss: 0.2270 - accuracy: 0.9184 - val_loss: 0.9619 - val_accuracy: 0.7352\n",
            "Epoch 15/20\n",
            "391/391 - 9s - loss: 0.2174 - accuracy: 0.9235 - val_loss: 0.9782 - val_accuracy: 0.7301\n",
            "Epoch 16/20\n",
            "391/391 - 9s - loss: 0.1998 - accuracy: 0.9298 - val_loss: 0.9784 - val_accuracy: 0.7351\n",
            "Epoch 17/20\n",
            "391/391 - 9s - loss: 0.1874 - accuracy: 0.9348 - val_loss: 1.0606 - val_accuracy: 0.7363\n",
            "Epoch 18/20\n",
            "391/391 - 9s - loss: 0.1717 - accuracy: 0.9404 - val_loss: 1.0278 - val_accuracy: 0.7334\n",
            "Epoch 19/20\n",
            "391/391 - 9s - loss: 0.1674 - accuracy: 0.9415 - val_loss: 1.0449 - val_accuracy: 0.7329\n",
            "Epoch 20/20\n",
            "391/391 - 9s - loss: 0.1532 - accuracy: 0.9453 - val_loss: 1.0581 - val_accuracy: 0.7313\n",
            "Elapsed time: 0:04:23.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xigd26XOoU-F"
      },
      "source": [
        "### Write your code in the cell below to print out the Precision, Recall,  F1 score, and classification_*report*\n",
        "\n",
        "### Include your findings in the project report. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_92T0bsfOgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3edd474a-aad3-4bd3-ba32-d9eca10ee917"
      },
      "source": [
        "from sklearn import metrics\n",
        "#from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_true = np.argmax(y_test,axis=1)\n",
        "pred = model.predict(x_test)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "\n",
        "\n",
        "score = metrics.accuracy_score(y_true, pred)\n",
        "print('Accuracy: {}'.format(score))\n",
        "\n",
        "\n",
        "f1 = metrics.f1_score(y_true, pred, average='weighted')\n",
        "print('Averaged F1: {}'.format(f1))\n",
        "\n",
        "           \n",
        "print(metrics.classification_report(y_true, pred))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7313\n",
            "Averaged F1: 0.7300723142465285\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.79      0.76      1000\n",
            "           1       0.84      0.81      0.82      1000\n",
            "           2       0.67      0.58      0.62      1000\n",
            "           3       0.56      0.54      0.55      1000\n",
            "           4       0.68      0.71      0.69      1000\n",
            "           5       0.64      0.64      0.64      1000\n",
            "           6       0.78      0.79      0.78      1000\n",
            "           7       0.79      0.78      0.79      1000\n",
            "           8       0.86      0.81      0.83      1000\n",
            "           9       0.76      0.86      0.81      1000\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.73      0.73     10000\n",
            "weighted avg       0.73      0.73      0.73     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "GFhqDiRNT715",
        "outputId": "bd7824a5-e80f-466d-ab9c-e83522f7aa41"
      },
      "source": [
        "cm = confusion_matrix(y_true, pred)\n",
        "print(cm)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm, ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] )\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[790  19  36  21  13   6   9  11  53  42]\n",
            " [ 17 811   3  12   2   0   6   5  17 127]\n",
            " [ 77   4 582  60  86  71  62  36   9  13]\n",
            " [ 34   9  55 535  65 177  67  27  16  15]\n",
            " [ 20   4  65  54 713  24  38  67  10   5]\n",
            " [ 15   5  42 160  57 643  25  40   5   8]\n",
            " [  5   6  51  57  54  22 788   5   8   4]\n",
            " [ 31   0  22  32  55  52   8 783   3  14]\n",
            " [ 59  47  12   8   5   7   6   3 811  42]\n",
            " [ 24  66   6  10   2   4   2  13  16 857]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-fed87bcc99d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'airplane'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'automobile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bird'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'frog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'horse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ship'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'truck'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_confusion_matrix' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "103RRPUvtOie"
      },
      "source": [
        "### Write your code in the cell below to show 3-5 images in the test set as well as their true labels and their labels predicted by your model.\n",
        "\n",
        "### Include your findings in the project report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFryw76VtOie"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgBnw9dRfOgS"
      },
      "source": [
        "\n",
        "\n",
        "## Part II:   CNN model with Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9rvtqrsfOgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "931b20ed-9cbb-4b05-f615-d116a525443a"
      },
      "source": [
        "# Load data again.The data split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_test shape:', y_test.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3)\n",
            "y_test shape: (10000, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGSxqVVypDiX"
      },
      "source": [
        "### Here we would like to use one pre-trained model called VGG16.   For more details on VGG16, please go to https://neurohive.io/en/popular-networks/vgg16/\n",
        "\n",
        "\n",
        "### VGG16 supports down to 48x48 images as an input. However, the resolution of our images is too low, which is (32, 32) so we need to increase the resolution.   This is called upsampling. \n",
        "\n",
        "\n",
        "\n",
        "### Find a way to do upsampling for each image to increase its resolution from 32x32 to 64x64. One option is to use the function resize(), which is provided by scikit-image library (https://scikit-image.org/)\n",
        "\n",
        "\n",
        "### Hints: \n",
        "\n",
        "#### (1) If you use resize() in scikit-image, that function also normalizes the input image so you may not want to normalize twice.\n",
        "\n",
        "#### Learn from the examples here:  https://scikit-image.org/docs/stable/auto_examples/transform/plot_rescale.html\n",
        "\n",
        "#### (2) Apply upsampling to x_train and x_test seperately. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWwBKsh-fOgX"
      },
      "source": [
        "import skimage.transform\n",
        "\n",
        "new_x_train = []\n",
        "\n",
        "for image in x_train:\n",
        "  newImage = skimage.transform.resize(image, (64, 64))      # note that resize() also normalizes your image\n",
        "  new_x_train.append(newImage)\n",
        "  \n",
        "\n",
        "# this process may take about a few minutes ...."
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdo8X_DME5dS"
      },
      "source": [
        "new_x_train = np.asarray(new_x_train)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u18mRo4ZE8wg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c12566d3-b6e0-4f3e-f4f0-9fdacf8c51ea"
      },
      "source": [
        "new_x_train.shape\n",
        "\n",
        "\n",
        "# expected output:  (50000, 64, 64, 3)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s0-oaKDfOgf"
      },
      "source": [
        "new_x_test = []\n",
        "\n",
        "\n",
        "for image in x_test:\n",
        "  newImage = skimage.transform.resize(image, (64, 64))\n",
        "  new_x_test.append(newImage)\n",
        "\n",
        "\n",
        "# this process may take about a few minutes ...."
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqTX5lJCFHaJ"
      },
      "source": [
        "new_x_test = np.asarray(new_x_test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zVob_JvFH5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9610a35c-9ff2-4d89-e19b-c3d1da6c21a9"
      },
      "source": [
        "new_x_test.shape\n",
        "\n",
        "\n",
        "# expected output:  (10000, 64, 64, 3)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPjFo2oyqlGO"
      },
      "source": [
        "### Write your code in the cell below to do the following:\n",
        "\n",
        "- First convert y_train and y_test from 2D to 1D by using reshape() function \n",
        "- Next apply one-hot encoding to y_train and y_test by using tf.keras.utils.to_categorical() function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQuVaf2pkRdr"
      },
      "source": [
        "# Convert y_train, y_test from 2D to 1D    \n",
        "y_train = y_train.reshape(50000)\n",
        "y_test = y_test.reshape(10000)\n",
        "\n",
        "# Convert class vectors to one hot format\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_pLuCNjqvbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ba4a29-bbbb-4a03-dc16-d9e0b539b979"
      },
      "source": [
        "# double check shape\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "\n",
        "# expected output:  (50000, 10)\n",
        "# expected output:  (10000, 10)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-bzRNdjfOgy"
      },
      "source": [
        "###  Load the pre-trained VGG16 model.  Write your code in the cell below to add each layer in VGG16 (excluding the top layers) to your new model.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HLwE00VfOgz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "d67e2bdc-24d2-4d02-fe29-35441acc3a84"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))   #  first hidden layer\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "  \n",
        "# write your code here\n",
        "\n",
        "\n",
        "for layer in vgg_model.layers:\n",
        "  model.add(layer)\n",
        "\n",
        "\n",
        "# print out the model summary\n",
        "model.summary()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4779b62c4c13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ki8D32hrl3E"
      },
      "source": [
        "### Write your code in the cell below to freeze the weights in each layer in the new model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_oqboGwfOg1"
      },
      "source": [
        "for layer in model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YArrSsS4rt_t"
      },
      "source": [
        "###  Write your code in the cell below to add some \"Dense\" layers as top layers.\n",
        "\n",
        "- Donot forget the output layer\n",
        "- Choose the right activation fucntion for the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fphbz0FhfOg3"
      },
      "source": [
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "# Add some \"Dense\" layers here, including output layer\n",
        "\n",
        "\n",
        "\n",
        "# Add some \"Dense\" layers here, including output layer\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDOG92fcr1m8"
      },
      "source": [
        "###  Write your code below for compile and fit. \n",
        "\n",
        "### Train your new model. \n",
        "\n",
        "### Notice that you should use earlystopping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWrWTc2JfOg6",
        "scrolled": false
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=Adam(learning_rate=0.001, decay=1e-6), metrics=['accuracy'])\n",
        "\n",
        "training = model.fit(new_x_train, y_train,     \n",
        "          batch_size=batch_size,\n",
        "          epochs=10,\n",
        "          verbose=2,\n",
        "          validation_data=(new_x_test, y_test))\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))\n",
        "\n",
        "\n",
        "\n",
        "# since we use GPU, the training time for each epoch for the transferred model is about 60 seconds.  \n",
        "# Let it run for a few epochs. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps2CZ8Xwrz_a"
      },
      "source": [
        "### Write your code below to print out the Precision, Recall, F1 score, and classification_report\n",
        "\n",
        "### Include your findings in the project report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMRuLfS3fOg8",
        "scrolled": true
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "\n",
        "y_true = np.argmax(y_test,axis=1)\n",
        "pred = model.predict(new_x_test)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "\n",
        "\n",
        "score = metrics.accuracy_score(y_true, pred)\n",
        "print('Accuracy: {}'.format(score))\n",
        "\n",
        "\n",
        "f1 = metrics.f1_score(y_true, pred, average='weighted')\n",
        "print('Averaged F1: {}'.format(f1))\n",
        "\n",
        "           \n",
        "print(metrics.classification_report(y_true, pred))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymp7tfFoFvjR"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true, pred)\n",
        "print(cm)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm, ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkatwrTod_ii"
      },
      "source": [
        "### Write your code in the cell below to show 3-5 images in the test set as well as their true labels and their labels predicted by your model with transfer learning. \n",
        "\n",
        "### Include your findings in the project report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoRepUWbd_ii"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "class_name = {\n",
        "    0: 'airplane',\n",
        "    1: 'automobile',\n",
        "    2: 'bird',\n",
        "    3: 'cat',\n",
        "    4: 'deer',\n",
        "    5: 'dog',\n",
        "    6: 'frog',\n",
        "    7: 'horse',\n",
        "    8: 'ship',\n",
        "    9: 'truck',\n",
        "}\n",
        "\n",
        "for i in range(5):\n",
        "  print(\"Prediction: %s\" % (class_name[pred[i]]))\n",
        "  print(\"Actual: %s\" % (class_name[y_true[i]]))\n",
        "  pixel_array = new_x_test[i].reshape(64,64,3)\n",
        "  pixel_array = (pixel_array*64)+64\n",
        "  pixel_array = pixel_array.astype(np.uint8)\n",
        "  img = Image.fromarray(pixel_array, 'RGB')\n",
        "  img = img.resize((256,256))\n",
        "  display(img)\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}